volumes:
  ingestion-volume-dag-airflow:
  ingestion-volume-dags:
  ingestion-volume-tmp:
  es-data:
  dbt-data:

services:
  mysql:
    container_name: dwh-openmetadata_mysql
    image: docker.getcollate.io/openmetadata/db:1.4.8
    command: "--sort_buffer_size=10M"
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: password
    ports:
      - "3306:3306"
    volumes:
      - ./docker-volume/db-data:/var/lib/mysql
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - openmetadata-network
    healthcheck:
      test: ["CMD-SHELL", "mysql --user=root --password=$MYSQL_ROOT_PASSWORD --silent --execute 'use openmetadata_db'"]
      interval: 15s
      timeout: 10s
      retries: 10

  elasticsearch:
    container_name: dwh-openmetadata_elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.2
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms1024m -Xmx1024m
      - xpack.security.enabled=false
    networks:
      - openmetadata-network
      - shared-network
    ports:
      - "9200:9200"
      - "9300:9300"
    healthcheck:
      test: "curl -s http://localhost:9200/_cluster/health?pretty | grep status | grep -qE 'green|yellow' || exit 1"
      interval: 15s
      timeout: 10s
      retries: 10
    volumes:
      - es-data:/usr/share/elasticsearch/data

  dbt:
    container_name: dwh-dbt
    image: python:3.11-slim
    environment:
      DBT_PROFILES_DIR: /dbt/mem_dwh  # Use absolute path for profiles.yml directory
    volumes:
      - dbt-data:/dbt  
    networks:
      - shared-network
    command: >
      sh -c "
      set -e &&
      apt-get update &&
      apt-get install -y git &&
      mkdir -p /dbt &&
      cd /dbt &&
      if git remote | grep -q origin; then
        git remote remove origin;
      fi &&
      git init &&
      git remote add origin https://github.com/NawalHamed/mem-dwh.git &&
      git config core.sparseCheckout true &&
      echo 'dbt/mem_dwh/*' > .git/info/sparse-checkout &&
      git pull origin main &&
      mv dbt/mem_dwh/* . &&
      pip install dbt-core dbt-postgres &&
      echo 'DBT container is ready and running.' &&
      sleep infinity
      "
    restart: "always"

  ingestion:
    container_name: dwh-openmetadata_ingestion
    image: docker.getcollate.io/openmetadata/ingestion:1.4.8
    depends_on:
      elasticsearch:
        condition: service_healthy
      mysql:
        condition: service_healthy
      openmetadata-server:
        condition: service_started
      dbt:
        condition: service_started
    environment:
      VIRTUAL_HOST: dwh-airflow.rihal.dev
      VIRTUAL_PORT: 8080
      AIRFLOW__API__AUTH_BACKENDS: "airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session"
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__OPENMETADATA_AIRFLOW_APIS__DAG_GENERATED_CONFIGS: "/opt/airflow/dag_generated_configs"
      DB_HOST: ${AIRFLOW_DB_HOST:-mysql}
      DB_PORT: ${AIRFLOW_DB_PORT:-3306}
      AIRFLOW_DB: ${AIRFLOW_DB:-airflow_db}
      DB_SCHEME: ${AIRFLOW_DB_SCHEME:-mysql+pymysql}
      DB_USER: ${AIRFLOW_DB_USER:-airflow_user}
      DB_PASSWORD: ${AIRFLOW_DB_PASSWORD:-airflow_pass}
      AIRFLOW__LINEAGE__BACKEND: airflow_provider_openmetadata.lineage.backend.OpenMetadataLineageBackend
      AIRFLOW__LINEAGE__AIRFLOW_SERVICE_NAME: local_airflow
      AIRFLOW__LINEAGE__OPENMETADATA_API_ENDPOINT: http://openmetadata-server:8585/api
      AIRFLOW__LINEAGE__JWT_TOKEN: ...
    entrypoint: /bin/bash
    command:
      - "/opt/airflow/ingestion_dependency.sh"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/v1/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    ports:
      - "8080:8080"
    networks:
      - openmetadata-network
      - shared-network
    volumes:
      - ingestion-volume-dag-airflow:/opt/airflow/dag_generated_configs
      - ingestion-volume-dags:/opt/airflow/dags
      - ingestion-volume-tmp:/tmp
      - dbt-data:/opt/airflow/dags/dbt

networks:
  openmetadata-network:
  shared-network:
    external: true
volumes:
  ingestion-volume-dag-airflow:
  ingestion-volume-dags:
  ingestion-volume-tmp:
  es-data:
  dbt-data:

services:
  mysql:
    container_name: dwh-openmetadata_mysql
    image: docker.getcollate.io/openmetadata/db:1.4.8
    command: "--sort_buffer_size=10M"
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: password
    ports:
      - "3306:3306"
    volumes:
      - ./docker-volume/db-data:/var/lib/mysql
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - openmetadata-network
    healthcheck:
      test: mysql --user=root --password=$$MYSQL_ROOT_PASSWORD --silent --execute "use openmetadata_db"
      interval: 15s
      timeout: 10s
      retries: 10

  elasticsearch:
    container_name: dwh-openmetadata_elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.2
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms1024m -Xmx1024m
      - xpack.security.enabled=false
    networks:
      - openmetadata-network
      - shared-network
    ports:
      - "9200:9200"
      - "9300:9300"
    healthcheck:
      test: "curl -s http://localhost:9200/_cluster/health?pretty | grep status | grep -qE 'green|yellow' || exit 1"
      interval: 15s
      timeout: 10s
      retries: 10
    volumes:
      - es-data:/usr/share/elasticsearch/data

  dbt:
    container_name: dwh-dbt
    image: python:3.11-slim
    environment:
      DBT_PROFILES_DIR: /dbt/mem_dwh
    volumes:
      - dbt-data:/dbt
    networks:
      - shared-network
    command: >
      sh -c "
      set -e &&
      apt-get update &&
      apt-get install -y git &&
      mkdir -p /dbt &&
      cd /dbt &&
      if git remote | grep -q origin; then
        git remote remove origin;
      fi &&
      git init &&
      git remote add origin https://github.com/NawalHamed/mem-dwh.git &&
      git config core.sparseCheckout true &&
      echo 'dbt/mem_dwh/*' > .git/info/sparse-checkout &&
      git pull origin main &&
      mv dbt/mem_dwh/* . &&
      pip install dbt-core dbt-postgres &&
      echo 'DBT container is ready and running.' &&
      sleep infinity
      "
    restart: "always"

  openmetadata-server:
    container_name: dwh-openmetadata_server
    image: docker.getcollate.io/openmetadata/server:1.4.8
    restart: always
    environment:
      VIRTUAL_HOST: dwh-openmetadata.rihal.dev
      VIRTUAL_PORT: 8585
      OPENMETADATA_CLUSTER_NAME: openmetadata
      SERVER_PORT: 8585
      SERVER_ADMIN_PORT: 8586
      LOG_LEVEL: INFO
      DB_DRIVER_CLASS: com.mysql.cj.jdbc.Driver
      DB_SCHEME: mysql
      DB_PARAMS: allowPublicKeyRetrieval=true&useSSL=false&serverTimezone=UTC
      DB_USER: openmetadata_user
      DB_USER_PASSWORD: openmetadata_password
      DB_HOST: mysql
      DB_PORT: 3306
      OM_DATABASE: openmetadata_db
      ELASTICSEARCH_HOST: elasticsearch
      ELASTICSEARCH_PORT: 9200
    depends_on:
      elasticsearch:
        condition: service_healthy
      mysql:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8585/api/v1/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - openmetadata-network
      - shared-network
    ports:
      - "8585:8585"
      - "8586:8586"

  ingestion:
    container_name: dwh-openmetadata_ingestion
    image: docker.getcollate.io/openmetadata/ingestion:1.4.8
    depends_on:
      elasticsearch:
        condition: service_healthy
      mysql:
        condition: service_healthy
      openmetadata-server:
        condition: service_started
      dbt:
        condition: service_started
    environment:
      VIRTUAL_HOST: dwh-airflow.rihal.dev
      VIRTUAL_PORT: 8080
      AIRFLOW__API__AUTH_BACKENDS: "airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session"
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__OPENMETADATA_AIRFLOW_APIS__DAG_GENERATED_CONFIGS: "/opt/airflow/dag_generated_configs"
      DB_HOST: mysql
      DB_PORT: 3306
      AIRFLOW_DB: airflow_db
      DB_SCHEME: mysql+pymysql
      DB_USER: airflow_user
      DB_PASSWORD: airflow_pass
      AIRFLOW__LINEAGE__BACKEND: airflow_provider_openmetadata.lineage.backend.OpenMetadataLineageBackend
      AIRFLOW__LINEAGE__AIRFLOW_SERVICE_NAME: local_airflow
      AIRFLOW__LINEAGE__OPENMETADATA_API_ENDPOINT: http://openmetadata-server:8585/api
    entrypoint: /bin/bash
    command:
      - "/opt/airflow/ingestion_dependency.sh"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/v1/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    ports:
      - "8080:8080"
    networks:
      - openmetadata-network
      - shared-network
    volumes:
      - ingestion-volume-dag-airflow:/opt/airflow/dag_generated_configs
      - ingestion-volume-dags:/opt/airflow/dags
      - ingestion-volume-tmp:/tmp
      - dbt-data:/opt/airflow/dags/dbt

networks:
  openmetadata-network:
  shared-network:
    external: true
